---
output: pdf_document
---
<!--
%\VignetteEngine{knitr::rmarkdown}
%\VignetteIndexEntry{How-to-use-the-EUFLOW-package}
-->


---
<<<<<<< HEAD:inst/How-to-use-this-package.Rmd
title: 'EUFLOW:'
author: "Kevin K. McDade"
date: "September 9, 2016"
output: pdf_document
subtitle: Expected Utility Workflow Evaluation Package
=======
title: "EUFLOW: Expected-Utility-based Workflow Evaluation"
author: "Kevin K. McDade"
date: "`r Sys.Date()`"
vignette: >
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteKeyword{EUFLOW}
  %\SweaveUTF8
  %\usepackage[utf8](inputenc)
output: 
    rmarkdown::html_vignette:
        toc: yes
>>>>>>> b14465839482afb2e774ee6fb04daaf40a92dda8:vignettes/How-to-use-the-EUFLOW-package.Rmd
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
library("EUFLOW")
options(stringsAsFactors = FALSE)
system("touch I_ran_Rmd")
```
### I.Introduction

The data in bioinformatics is often in some “raw” form which is not yet ready for analysis. 
Processing this data often involves several steps, called variously a workflow, pipeline, or protocol. 
REWRITE THE REST OF THIS.
One major obstacle to data reproducibility is workflows are rarely identical and the differences between workflow steps may not be the optimal way to process the data. 
We define a workflow here as a series of steps that a user takes to arrive at the analysis goal. 
The magnitude of the path choices can be considered to be a great benefit to the analyst, however, it is often the case that the user does not know which path to take.   

In regards to bioinformatics workflow options can include ready-to-go data (a finished data set), custom workflows (user decides what steps to take), or use of a tuning parameter (i.e. requiring a certain level of data quality).  Any change in a workflow step or change of a parameter setting constitutes a new workflow option.  To what extent do these choices affect the final dataset to be analyzed? If the datasets differ substantially, will they differ in quality? If so, how can we tell which is best?  Finally, will soundness of the scientific conclusions be harmed by worse workflow options? Surprisingly little is known.  




The contents of this package are:
```{r}
search() 

```

```{r}
ls(pos=2)
```

We now test the package using How-touse-this-package.Rmd contents.

Users are required to input two separate data files, regardless of the analysis type. The EUFLOW package depends upon a model quality heuristic which we will demonstate here as correlation between gene expression and protein expression. The first data file, for example, we will use ovarian TCGA RNASeq data on two separate workflows provided on the same samples. Only samples for which protein expression data was available are used in the RNASEQDATA file.

A small slice of this data file (RNASEQDATA) demonstrates the data structure of numbered row names followed by a column of identifiers including a tag _v1 and _v2. The same samples were processed with two different workflow options RnaSeqv1 and RnaSeqv2. The output below shows the gene expression values for the first 9 identifiers (in this case gene names) with a tag to distinguish workflow option. For brevity only 4 of the 198 sample identifiers are represented.


```{r}
data(RNASEQDATA)
RNASEQDATA[1:9,1:5]
RNASEQDATA[68:77,1:5]
```

In the second data file we will use TCGA protein expression data on the sampe samples. As above we will output only a subset. Alos note that as this is the reference dataset in this example only one identifier is represented rather than multiple workflow options.   
```{r}
data(RPPADATA.original)
RPPADATA<-RPPADATA.original
RPPADATA[1:9,1:5]
```
We now have all that is required to run the EUFLOW package. For the purpose of clarity we define the RNASEQDATA set as the EvaluationExperimentSet, which includes 2 workflow options (RnaSeqV1 and RnaSeqv2). We also define the RPPADATA as the ReferenceSet. If it is the choice of the user multiple reference sets can be utilized. 

```{r}

EvaluationExperimentSet<-RNASEQDATA
ReferenceSet<-RPPADATA
```

<<<<<<< HEAD:inst/How-to-use-this-package.Rmd
Now that we have the data for our example, the WorkflowEvaluationData function will modify the separate dataframes into one data structure to prepare to calcuate the model quality and perform the evaluation. The first item in the list is the Reference data and the second item in the list is the evaluation data.


```{r,eval=FALSE}
>>>>>>> b14465839482afb2e774ee6fb04daaf40a92dda8:vignettes/How-to-use-the-EUFLOW-package.Rmd

Workflow.Data<-WorkflowEvaluationData(EvaluationExperimentSet,ReferenceSet)
Workflow.Data[[1]][1:9,1:5]

```
Further data processing to determine the number of workflow options and structure tags will be used to name the output by creating a Merged.options object.

```{r}
Workflow.Data<-WorkflowEvaluationData(EvaluationExperimentSet,ReferenceSet)
Workflow.Data[[1]][1:9,1:5]
Merged.options<-merge_tag_options(Workflow.Data)
Merged.options[1:9,1:5]
```
The Model.quality.object is created to create a map between the Reference ids and the evaluation ids using the Model.quality.list function.

```{r}
Model.quality.object<-Model.quality.list(Merged.options)

```
Next, Model Quality is an object which contains the model quality values for each of the pairs. How the Model quality is determined is specified by the user.
```{r}
Model.Quality<-Workflow.Criterion(Model.quality.object,method="pearson")
head(as.data.frame(Model.Quality))
```
```{r}
Model.Quality<-Workflow.Criterion(Model.quality.object,method="spearman")
head(as.data.frame(Model.Quality))
```

```{r}
Posterior.dataframe<-Workflow.posteriorestimate(Model.quality.object,Model.Quality)

```

```{r}
Workflow.Evaluation.table(Posterior.dataframe)
Workflow.Evaluation.table(Posterior.dataframe,deltaPlus = 2)
Workflow.Evaluation.table(Posterior.dataframe,Utp=3)
Workflow.Evaluation.table(Posterior.dataframe,Utp=1)
```
